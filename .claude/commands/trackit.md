---
name: trackit
description: Monitor any long-running job, handle failures, and create a PR with results when done. Use when the user says "trackit" for any job they want tracked — sbatch, background process, or multi-step pipeline.
tools: Read, Write, Edit, Bash, Glob, Grep, Task
---

Track a long-running job to completion and create a PR with results.

## How to get context

1. Identify what's running: SLURM job ID, background PID, or a command to launch
2. Find the experiment doc (usually in `docs/`) and results directory
3. Determine how to check status and where logs/results land
4. Detect environment: check if `squeue` exists (Sherlock/HPC) or if this is a local machine

## Steps

1. **Launch** (if not already running):
   - **On Sherlock / HPC** (i.e. `squeue` is available):
     - If the repo has a `sherlock-dispatch` workflow (`gh workflow view sherlock-dispatch.yml`),
       prefer submitting via: `gh workflow run sherlock-dispatch.yml -f script=<script.sh> -f wandb_run=<name>`.
       This triggers the full submit → monitor → collect pipeline on the self-hosted runner.
     - Otherwise, submit directly with `sbatch`.
   - **On local machine** (no SLURM):
     - Run the command directly, or as a background process (`nohup ... &`).
     - If the job targets a remote cluster, use `ssh` or `gh workflow run` to dispatch.
2. **Create PR immediately** (do not wait for completion):
   - Branch: `git checkout -b results/<experiment>-<date>`
   - Update experiment docs with a results table showing jobs as PENDING
   - Commit and push
   - `gh pr create` with a summary of what's being tracked
3. **Monitor**: Poll status in background agents until completion
   - SLURM: `squeue -j <jobid>`, then `sacct -j <jobid> --format=JobID,State,ExitCode,Elapsed`
   - GitHub workflow: `gh run list --workflow=sherlock-dispatch.yml` to check dispatch status
   - Background process: `ps -p <pid>`, check log files
   - Any job: check output files, log tails, exit codes
4. **Diagnose failures**: If it failed, read logs, fix the issue, relaunch. Repeat up to 3 times.
5. **Collect results**: Read output files (json, jsonl, csv, logs, etc.)
6. **Update PR**: Push new commits to the results branch with actual metrics
   - Update the results table in experiment docs (replace PENDING with actual values)
   - Add discussion section if appropriate
   - Push to the existing branch — the PR updates automatically

## PR format

```bash
gh pr create \
  --title "Results: <experiment name>" \
  --body "$(cat <<'EOF'
## Summary
<1-3 bullet points describing what's being tracked>

## Status
Jobs are PENDING / RUNNING. Results will be updated in this PR.

## Metrics to collect
<list target metrics>

## Test plan
- [ ] Job <id> completes successfully
- [ ] Results tables updated with actual metrics
- [ ] Discussion section filled in

Generated by /trackit skill.
EOF
)"
```

## Failure handling

- Read error logs to diagnose
- Common issues: OOM, missing deps, path errors, timeouts, container failures
- Fix and relaunch, up to 3 attempts
- After 3 failures, write a failure report and update the PR anyway

## Important

- Create the PR FIRST, then monitor — the user gets a tracking artifact immediately
- On HPC: prefer `gh workflow run sherlock-dispatch.yml` when available, fall back to direct `sbatch`
- On local: just run the process directly
- Do NOT ask the user for feedback during monitoring — handle issues autonomously
- Commit with `Co-Authored-By: Claude Opus 4.6 <noreply@anthropic.com>`

Report at the end with a concise summary and a link to the PR.
